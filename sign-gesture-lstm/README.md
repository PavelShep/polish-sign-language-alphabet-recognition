# sign-gesture-lstm

Skrypty dla trenowania modelu do rozpoznawania gest贸w doni oraz ich wykrywanie w czasie rzeczywistym z u偶yciem kamery internetowej.
Model oparty jest na sieci neuronowej LSTM i wykorzystuje punkty kluczowe doni (hand landmarks).

---

## Wymagania

- Python **3.10.11**
- Kamera internetowa
- System Windows (instrukcje poni偶ej dla Windows)

---

## Instalacja i uruchomienie

### 1锔 Jeli tworzysz rodowisko od zera

Utw贸rz wirtualne rodowisko:

```bash
python -m venv venv
```

Aktywuj rodowisko:

```bash
venv\Scripts\activate
```

Zainstaluj wymagane biblioteki:

```bash
pip install -r requirements.txt
```

### 2锔 Jeli rodowisko ju偶 istnieje

Aktywuj je:

```bash
venv\Scripts\activate
```

---

## Proces trenowania modelu

###  1. Zbieranie danych

Uruchom:

```bash
python collect_data.py
```

Skrypt zapisuje sekwencje punkt贸w doni do folderu `data/`.

![Interfejs okna przygotowania do nagrywania](photo_trening.png)

###  2. Trenowanie modelu

```bash
python train_model.py
```

Po zakoczeniu treningu zostanie wygenerowany plik modelu (np. `model.h5`).

###  3. Rozpoznawanie gest贸w w czasie rzeczywistym

```bash
python detect_live.py
```

Program uruchamia kamer i wywietla przewidywan liter alfabetu PJM.

###  4. Ewaluacja modelu (rednia skuteczno)

Aby sprawdzi dokadno modelu:

```bash
python evaluate_model.py
```

Skrypt wywietli:

- dokadno (accuracy)
- macierz pomyek (confusion matrix)
- inne metryki klasyfikacji

---

## Struktura

```
 data/                # Zebrane dane (sekwencje punkt贸w doni)
 model.h5             # Wytrenowany model
 collect_data.py      # Zbieranie danych
 train_model.py       # Trenowanie modelu
 detect_live.py       # Rozpoznawanie w czasie rzeczywistym
 evaluate_model.py    # Ewaluacja modelu
 requirements.txt     # Lista zale偶noci
 README.md
```

---

## Informacje dodatkowe

- Model wykorzystuje sekwencje punkt贸w kluczowych doni (21 landmark贸w).
- Sie LSTM analizuje zale偶noci czasowe w ruchu doni.
- Skuteczno modelu zale偶y od jakoci i liczby zebranych danych.
